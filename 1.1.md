了解Spark

Apache Spark是一个强大的开源处理引擎。它提供MapReduce的灵活性和可扩展性，但速度明显更高;当数据存储在内存中时，它比Apache Hadoop快100倍，访问磁盘时高达10倍。

Apache Spark允许用户读取、转换、聚合数据，还可以轻松地训练和部署复杂的统计模型。Java、Scala、Python 、R和SQL都可以访问Spark API。
Apache Spark可用于构建应用程序，或将其打包成为要部署在集群上的库，或通过笔记本(notebook) （例如Jupyter、Spark-Notebook、Databricks notebooks 和 Apache Zeppelin）交互式执行快速的分析。

Apache Spark提供的很多库会让那些使用过Python的pandas或R语言的data.frame或者data.tables的数据分析师、数据科学家或研究人员觉得熟悉。
非常重要的一点是，虽然Spark DataFrame 会让pandas或data.frame、data.tables用户感到熟悉，但是仍有一些差异，所以不要期望过高。


具有更多SQL使用背景的用户也可以用该语言来塑造其数据。此外，Apache Spark还提供了几个已经实现并调优过的算法、统计模型和框架: 为机器学习
提供的MLlib和ML，为图形处理提供的GraphX和GraphFrames，以及Spark Streaming (DStream和Structured)。
Spark允许用户在同一个应用程序中随意地使用这些库。

Apache Spark可以方便地在本地笔记本电脑上运行，而且还可以轻松地独立模式下通过YARN或Apache Mesos于本地集群或云中进行部署。
它可以从不同的数据源读取和写入，包括HDFS、Casandra、Hbase和S3.

