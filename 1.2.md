## Spark作业和API
在本节中，我们将简要介绍Apache Spark作业和API。这为Spark2.0架构的后续部分提供了必要的基础。

### 1.2.1 执行过程
任何Spark应用程序都会分离主节点上的单个驱动进程(可以包含多个作业)，然后将执行进程（包含多个任务）分配给多个工作节点。
驱动进程会确定任务进程的数量和组成，这些任务进程是根据为指定作业生成的图形分配给执行节点的。注意，任何工作节点都可以来自多个不同作业的多个任务。
Spark作业与一系列对象依赖相关联，这些依赖关系是以有向无环图（DAG）的方式组织的。例如从Spark UI生成的以下示例。基于这些，Spark可以优化调度（例如确定所需的任务和工作节点的数量）并执行这些任务。

### 1.2.2 弹性分布式数据集
弹性分布式数据集（简称RDD）是不可变JAVA虚拟机（JVM）对象的分布式集合，Apache Spark围绕着RDD而构建的。我们使用Python时，尤为重要的是要注意Python数据是存储在这些JVM对象中的。这些对象允许作业非常快速地执行计算。对RDD的计算依据缓存和存储在内存中的模式进行：与其他传统分布式框架（Apache Hadoop）相比，该模式使得计算速度快了一个数量级。

同时，RDD会给出一些粗粒度的数据转换（例如map(...), reduce(...)和filter(...) ）保持Hadoop平台的灵活性和可扩展性，以执行各种各样的计算。RDD以并行方式应用和记录数据转换，从而提高了速度和容错能力。通过注册这些转换，RDD提供数据沿袭--以图形形式给出的每个中间步骤的祖先树。这实际上保护RDD的分区丢失，它依然具有足够的信息来重新创建该分区，而不是简单地依赖复制。

RDD有两组并行操作：转换（返回指向新RDD的指针）和动作（在运行计算后驱动程序返回值）。

在某些意义上说，RDD转换操作是惰性的，因为他们不立即执行计算器结果，只有动作执行了并且需要将结果返回给驱动程序时，才会计算转换。该延迟执行会产生更多精细查询：针对性能进行优化的查询，这种优化始于Apache Spark的DAGScheduler--面向阶段的调度器。由于具有单独的RDD转换和动作，DAGScheduler可以在查询中执行优化，包括能够避免shuffle数据（最耗费资源的任务）。

### 1.2.3 DataFrame
TODO
