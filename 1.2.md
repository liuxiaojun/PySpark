## Spark作业和API
在本节中，我们将简要介绍Apache Spark作业和API。这为Spark2.0架构的后续部分提供了必要的基础。

### 1.2.1 执行过程
任何Spark应用程序都会分离主节点上的单个驱动进程(可以包含多个作业)，然后将执行进程（包含多个任务）分配给多个工作节点。
驱动进程会确定任务进程的数量和组成，这些任务进程是根据为指定作业生成的图形分配给执行节点的。注意，任何工作节点都可以来自多个不同作业的多个任务。
Spark作业与一系列对象依赖相关联，这些依赖关系是以有向无环图（DAG）的方式组织的。例如从Spark UI生成的以下示例。基于这些，Spark可以优化调度（例如确定所需的任务和工作节点的数量）并执行这些任务。

### 1.2.2 弹性分布式数据集
弹性分布式数据集（简称RDD）是不可变JAVA虚拟机（JVM）对象的分布式集合，Apache Spark围绕着RDD而构建的。我们使用Python时，尤为重要的是要注意Python数据是存储在这些JVM对象中的。这些对象允许作业非常快速地执行计算。对RDD的计算依据缓存和存储在内存中的模式进行：与其他传统分布式框架（Apache Hadoop）相比，该模式使得计算速度快了一个数量级。

同时，RDD会给出一些粗粒度的数据转换（例如map(...), reduce(...)和filter(...) ）保持Hadoop平台的灵活性和可扩展性，以执行各种各样的计算。RDD以并行方式应用和记录数据转换，从而提高了速度和容错能力。通过注册这些转换，RDD提供数据沿袭--以图形形式给出的每个中间步骤的祖先树。这实际上保护RDD的分区丢失，它依然具有足够的信息来重新创建该分区，而不是简单地依赖复制。

RDD有两组并行操作：转换（返回指向新RDD的指针）和动作（在运行计算后驱动程序返回值）。

在某些意义上说，RDD转换操作是惰性的，因为他们不立即执行计算器结果，只有动作执行了并且需要将结果返回给驱动程序时，才会计算转换。该延迟执行会产生更多精细查询：针对性能进行优化的查询，这种优化始于Apache Spark的DAGScheduler--面向阶段的调度器。由于具有单独的RDD转换和动作，DAGScheduler可以在查询中执行优化，包括能够避免shuffle数据（最耗费资源的任务）。

### 1.2.3 DataFrame
DataFrame像RDD一样，是分布在集群的节点中的不可变数据集合。然而，与RDD不同的是，在DataFrame中，数据释义命名列的方式组织的。

DataFrame旨在使大型数据集的处理更加容易。它们允许开发人员对数据结构进行形式化，允许更高级的抽象。在这个意义上来说，DataFrame与关系数据库中的表类似。DataFrame提供了一个特定领域的语言API来操作分布式数据，使Spark可以被更广泛的受众使用，而不只是专门的数据工程师。

DataFrame的一个主要特点是，Spark引擎一开始就构建了一个逻辑执行计划，而执行生成的代码是基于成本优化程序确定的物理计划。与Java或者Scala相比，Python中的RDD是非常慢的，而DataFrame的引入则使性能在各种语言中都保持稳定。

### 1.2.4 DataSet
Spark1.6中引入的Spark Dataset旨在提供一个API，允许用户轻松地表达域对象的转换，同时还提供了具有强大性能和优点的Spark SQL执行引擎。遗憾的是，在写这篇文章的时候，DataSet只能在Scala或者Java中可用。

### 1.2.5 Catalyst优化器
Spark SQL是Apache Spark最具有技术性的组件之一，因为它支持SQL查询和DataFrame API。Spark SQL的核心是Catalyst优化器。优化器基于函数式编程结构，并且旨在实现两个目的： 简化向Spark SQL添加新的优化技术和特性的条件，并允许外部开发人员扩展优化器（例如，添加数据源特定规则，支持新的数据类型等等）；

### 1.2.6 钨丝计划
Tungten是Apache Spark执行引擎项目的代号。该项目的重点是改进Spark算法，使它们更有效地使用内存和CPU，使现在硬件的性能发挥到极致。

该项目的工作重点包括：
* 显示管理内存，以消除JVM对象模型和垃圾回收的开销。
* 设计利用内存层次结构的算法和数据结构。
* 在运行时生成代码，以便应用程序可以利用现代编译器并优化CPU。
* 消除虚拟函数调度，以减少多个CPU调用。
* 利用初级编程（例如，将即时数据加载到CPU寄存器），以加速内存访问并优化Spark的引擎，以有效地变异和执行简单循环。
