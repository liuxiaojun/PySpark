## Spark2.0的架构
Apache Spark2.0的引入是Apache Spark项目基于过去两年平台开发经验近期发布的主要版本更新。
Apache Spark2.0 发布的是哪个重要主题包括性能增强（通过Tungsten Phase 2）、引入结构化流以及统一DataSet和DataFrame。虽然DataSet目前只能在Scala和Java中使用。

### 1.3.1 统一DataSet和DataFrame
DataSet的目标是提供一个类型安全的编程接口。这允许开发人员使用编译时类型安全（生产应用程序可以在运行之前检查错误）处理半结构化数据（例如JSON或键值对）。Python不实现DataSet API的部分原因是Python不是一种类型安全的语言。

同样重要的是，DataSet API包含高级别域的特定语言操作，例如sum(),avg(),join()和group(). 这种最新的特性意味着不仅具有传统Spark RDD的灵活性，而且代码也更容易表达、读取和写入。与DataFrame类似，DataSet可以通过将表达式和数据字段宝楼给查询计划器并借助Tungten的快速内存编码来运用Spark的Catalyst优化器。


### 1.3.2  SparkSession介绍
在过去，你可能会使用SparkConf，SparkContext，SQLContext和HiveContext来分别执行配置，Spark环境，SQL环境和Hive环境的各种Spark查询。

SparkSession本质上是这些环境的组合，包括StreamingContext。
例如过去我们这样写
```
df=sqlContext.read.format('json').load('/py/test/sql/people.json')
```
现在可以这样写
```
df=spark.read.format('json').load('/py/test/sql/people.json')
```
或者这样写
```
df=spark.read.json('/py/test/sql/people.json')
```
SparkSession现在读取数据、处理元数据、配置会话和管理集群资源的入口。


### 1.3.3 Tungsten Phase2
当项目开始时，对计算机硬件环境的基本观察是，尽管内存、磁盘和网络接口（在一定程度上）的性价比并非如此。虽然硬件制造商可以在每个插槽中放置更多的核心（即通过并行化提供性能），但是实际核心速度没有显著的改进。

Project Tungsten与2015年推出，改进的侧重方面：
内存管理和二进制管理： 利用应用程序予以来显试管理内存，并消除JVM对象木星和来及回收的开销。
高速缓存感知计算：利用存储器层次结构的算法和数据结构。
代码生成： 使用代码生成来利用现代编译器和CPU。
没有虚拟函数调用：减少了多次CPU调用，这在调度数十亿次运算时可能对性能产生深远的影响。
存储器中的中间数据对比CPU寄存器中的中间数据： Tungsten Phase2将中间数据放入CPU寄存器。从CPU寄存器而不是从存储器上获得数据使读取数据的周期数得到了数量级的提升。
新欢展开和SIMD：优化Apache Spark的执行引擎，以利用现在编译器和CPU有效地变异和执行简单for循环。

### 1.3.4 结构化流
这是构建结构化流的基础。虽然流媒体功能强大，但关键问题之一是流可以难以构建和维护。
高级流API构建在Apache Spark SQL引擎智商。它运行的查询和使用DataSet、DataFrame时完全相同，为你提供所有性能和优化以及事件事件窗口、会话、源和sink等方面的优势。
